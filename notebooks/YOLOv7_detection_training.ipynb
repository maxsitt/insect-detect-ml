{"cells":[{"cell_type":"markdown","metadata":{"id":"NMauZMalbLl7"},"source":["<img src=\"https://raw.githubusercontent.com/maxsitt/insect-detect-docs/main/docs/assets/logo.png\" width=\"500\">\n","\n","# YOLOv7 detection model training for deployment on Luxonis OAK\n","\n","Author: &nbsp; Maximilian Sittinger &nbsp;\n","[<img src=\"https://github.githubassets.com/images/modules/logos_page/GitHub-Mark.png\" width=\"24\">](https://github.com/maxsitt) &nbsp;\n","[<img src=\"https://upload.wikimedia.org/wikipedia/commons/0/06/ORCID_iD.svg\" width=\"24\">](https://orcid.org/0000-0002-4096-8556)\n","\n","- ðŸ“‘ [**Insect Detect Docs**](https://maxsitt.github.io/insect-detect-docs/)\n","- [`insect-detect-ml` GitHub repo](https://github.com/maxsitt/insect-detect-ml)\n","\n","&nbsp;\n","\n","**Train a [YOLOv7](https://github.com/WongKinYiu/yolov7) object detection model on your own custom training data!**\n","\n","- Using dataset import from [Roboflow](https://roboflow.com/) is recommended, but is not required.\n","> Choose option *Upload dataset from Google Drive/local file system* instead (slower!).\n","- Connecting to Google Drive is recommended, but is not required.\n","> Choose options *Upload dataset from your local file system* and *Download* instead of *Export to Google Drive* (slower!).\n","- Go to **File** in the top menu bar and choose **Save a copy in Drive** before running the notebook.\n","- Go to **Runtime** and make sure that **GPU** is selected as Hardware accelerator under **Change runtime type**.\n","- If you are using Firefox, please make sure to allow notifications for this website.\n","\n","&nbsp;\n","\n","---\n","\n","**References**\n","\n","1. Roboflow tutorial notebook for YOLOv7 training &nbsp;\n","[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/roboflow-ai/notebooks/blob/main/notebooks/train-yolov7-object-detection-on-custom-data.ipynb)\n","2. DepthAI tutorial notebook for YOLOv7 training &emsp;\n","[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/luxonis/depthai-ml-training/blob/master/colab-notebooks/YoloV7_training.ipynb)"]},{"cell_type":"markdown","metadata":{"id":"3q8IjnB8QGG3"},"source":["# Initialization"]},{"cell_type":"markdown","metadata":{"id":"pbdTb-q4QJ0M"},"source":["## Show GPU + Linux distribution"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"MsJ9oBX1dUhh"},"outputs":[],"source":["!nvidia-smi -L\n","print(\"\\n\")\n","!head -n 2 /etc/*release"]},{"cell_type":"markdown","metadata":{"id":"wVi4j857p0GS"},"source":["## YOLOv7 setup"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"P1F_lwcyqItL"},"outputs":[],"source":["!git clone https://github.com/WongKinYiu/yolov7.git\n","%cd yolov7\n","%pip install -qr requirements.txt\n","!wget https://github.com/WongKinYiu/yolov7/releases/download/v0.1/yolov7-tiny.pt"]},{"cell_type":"markdown","metadata":{"id":"g41kdogczKts"},"source":["## Recommended: Upload dataset from Roboflow\n","\n","If you are not sure how to export your annotated dataset in YOLOv7 format, check the [Roboflow docs](https://docs.roboflow.com/exporting-data).\n","\n","> Alternatively you can upload your dataset ([YOLOv7 format](https://roboflow.com/formats/yolov7-pytorch-txt)) from **[Google Drive](#scrollTo=RxOnnOadc5vR)** or from your **[local file system](#scrollTo=qKTCWdtkOUw7)** in the next steps!"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"aRSmjO9MQRVq"},"outputs":[],"source":["%pip install -q roboflow==0.2.34\n","from roboflow import Roboflow\n","rf = Roboflow(model_format = \"yolov7\", notebook = \"insdet_yolov7\")"]},{"cell_type":"markdown","metadata":{"id":"8cqOYoopQx-U"},"source":["**Copy only the last three lines of the Download Code and insert them at the top of the next code cell:**"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"0SsPwQDzRvwH"},"outputs":[],"source":["### Paste your Download Code here:\n","rf = Roboflow(api_key=\"XXXXXXXXXXXXXXXXXXXX\")\n","project = rf.workspace(\"maximilian-sittinger\").project(\"insect_detect_detection\")\n","dataset = project.version(7).download(\"yolov7\")\n","###\n","\n","dataset_location = dataset.location\n","\n","from pathlib import Path\n","print(f\"\\nLocation of dataset: {dataset_location}\\n\")\n","print(\"Number of training images:\", len(list(Path(f\"{dataset_location}/train/images\").glob(\"*.jpg\"))))\n","print(\"Number of validation images:\", len(list(Path(f\"{dataset_location}/valid/images\").glob(\"*.jpg\"))))\n","print(\"Number of test images:\", len(list(Path(f\"{dataset_location}/test/images\").glob(\"*.jpg\"))))\n","print(\"\\nContent of data.yaml file:\\n\")\n","%cat {dataset_location}/data.yaml"]},{"cell_type":"markdown","metadata":{"id":"RxOnnOadc5vR"},"source":["## Recommended: Connect to Google Drive"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"q4lMoPNddCtx"},"outputs":[],"source":["from google.colab import drive\n","drive.mount(\"/content/drive\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"hFA-ROJ8rUWU"},"outputs":[],"source":["#@title ## Optional: Upload dataset from Google Drive {display-mode: \"form\"}\n","\n","#@markdown ### Google Drive path to dataset folder:\n","dataset_path = \"MyDrive/Datasets/yolov7_dataset\" #@param {type: \"string\"}\n","\n","%cp -ai /content/drive/{dataset_path} /content/yolov7\n","\n","from pathlib import Path\n","dataset_name = Path(dataset_path).stem\n","dataset_location = f\"/content/yolov7/{dataset_name}\"\n","\n","print(f\"Location of dataset: {dataset_location}\\n\")\n","print(\"Number of training images:\", len(list(Path(f\"{dataset_location}/train/images\").glob(\"*.jpg\"))))\n","print(\"Number of validation images:\", len(list(Path(f\"{dataset_location}/valid/images\").glob(\"*.jpg\"))))\n","print(\"Number of test images:\", len(list(Path(f\"{dataset_location}/test/images\").glob(\"*.jpg\"))))\n","print(\"\\nContent of data.yaml file:\\n\")\n","%cat {dataset_location}/data.yaml"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"qKTCWdtkOUw7"},"outputs":[],"source":["#@title ## Optional: Upload dataset from your local file system {display-mode: \"form\"}\n","\n","#@markdown ### Name of your (zipped) dataset folder:\n","dataset_name = \"yolov7_dataset\" #@param {type: \"string\"}\n","#@markdown - Please make sure to compress your dataset folder to **.zip file** before uploading!\n","#@markdown - The name of the .zip file should be the same as for the dataset folder.\n","#@markdown - Dataset has to be in [YOLOv7 format](https://roboflow.com/formats/yolov7-pytorch-txt).\n","\n","dataset_location = f\"/content/yolov7/{dataset_name}\"\n","\n","from google.colab import files\n","uploaded = files.upload()\n","\n","import zipfile\n","if len(list(zipfile.Path(f\"{dataset_name}.zip\").iterdir())) > 1:\n","  !unzip -uq {dataset_name}.zip -d /content/yolov7/{dataset_name}\n","else:\n","  !unzip -uq {dataset_name}.zip -d /content/yolov7\n","%rm {dataset_name}.zip\n","\n","from pathlib import Path\n","print(f\"\\nLocation of dataset: {dataset_location}\\n\")\n","print(\"Number of training images:\", len(list(Path(f\"{dataset_location}/train/images\").glob(\"*.jpg\"))))\n","print(\"Number of validation images:\", len(list(Path(f\"{dataset_location}/valid/images\").glob(\"*.jpg\"))))\n","print(\"Number of test images:\", len(list(Path(f\"{dataset_location}/test/images\").glob(\"*.jpg\"))))\n","print(\"\\nContent of data.yaml file:\\n\")\n","%cat {dataset_location}/data.yaml"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"uv36pkEtMupF"},"source":["## Optional: Edit `data.yaml`\n","\n","If you chose to upload your training dataset from **Google Drive** or your **local file system**, you have to check the `data.yaml` file in your dataset folder to make sure the paths to the train, valid and test folders are correct.\n","\n","- Open your dataset folder in the File Explorer (Folder symbol on the left side bar).\n","- Double-click on the `data.yaml` file, it will open in the editor to the right.\n","\n","  Make sure that the paths to the train, valid and test folders are as follows:\n","\n","  ```\n","  train: <YOUR_DATASET_NAME>/train/images\n","  val: <YOUR_DATASET_NAME>/valid/images\n","  test: <YOUR_DATASET_NAME>/test/images\n","  ```\n","\n","- Insert the correct name of your dataset folder at `<YOUR_DATASET_NAME>`.\n","- Save your changes with **Ctrl + S** and close the editor."]},{"cell_type":"markdown","metadata":{"id":"nnn4pSbI6eTv"},"source":["# Model training"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"fiHezxt98x_Z"},"source":["## Optional: Install [Weights & Biases](https://docs.wandb.ai/) as external logger"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"107tQ8Pu8Z1l"},"outputs":[],"source":["%pip install -q wandb\n","import wandb\n","wandb.login()"]},{"cell_type":"markdown","metadata":{"id":"U4t4JhGYGOcr"},"source":["## Tensorboard logger\n","\n","> If you are using Firefox, **disable Enhanced Tracking Protection** for this website (click on the shield to the left of the address bar) for the Tensorboard logger to work correctly!"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"lYCUyGITGU6j"},"outputs":[],"source":["%load_ext tensorboard\n","%tensorboard --logdir /content/yolov7/runs/train"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"7t6PUcz3SsEy"},"source":["## Train YOLOv7-tiny detection model\n","\n","- `--name` name of the training run\n","- `--img` input image size (recommended: same size as for inference)\n","- `--batch` specify batch size (recommended: 32)\n","- `--epochs` set the number of training [epochs](https://machine-learning.paperspace.com/wiki/epoch) (recommended: 100-300+ epochs)\n","- `--data` path to `data.yaml` file\n","- `--weights` specify the pretrained model weights\n","> `--weights \"yolov7-tiny.pt\"` YOLOv7-tiny model for inference on OAK\n","- `--cfg` path to `model.yaml` file\n","- `--hyp` path to hyperparameters\n","\n","> More information on YOLOv7 [model training](https://blog.roboflow.com/yolov7-custom-dataset-training-tutorial/#training-the-yolov7-with-custom-data) ðŸš€"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"qAYNJg9M7sg3"},"outputs":[],"source":["training_run_name = \"YOLOv7tiny_320_batch32_epochs300\" #@param {type: \"string\"}\n","#@markdown **Add UTC timestamp in front of training run name:**\n","add_timestamp = True #@param {type:\"boolean\"}\n","#@markdown ---\n","\n","image_size = 320 #@param {type: \"integer\"}\n","batch_size = 32 #@param {type:\"slider\", min:16, max:128, step:16}\n","number_epochs = 300 #@param {type:\"slider\", min:10, max:600, step:10}\n","\n","if add_timestamp == True:\n","  from datetime import datetime\n","  utc_timestamp = datetime.now().strftime(\"%Y%m%d_%H-%M\")\n","  train_run_name = f\"{utc_timestamp}_{training_run_name}\"\n","else:\n","  train_run_name = training_run_name\n","\n","%cd /content/yolov7\n","\n","!python train.py \\\n","--name {train_run_name} \\\n","--img {image_size} {image_size} \\\n","--batch {batch_size} \\\n","--epochs {number_epochs} \\\n","--data {dataset_location}/data.yaml \\\n","--weights \"yolov7-tiny.pt\" \\\n","--cfg cfg/training/yolov7-tiny.yaml \\\n","--hyp data/hyp.scratch.tiny.yaml"]},{"cell_type":"markdown","metadata":{"id":"iCYZ30f36gKs"},"source":["### View metrics plots"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"6GMLKLak6iTq"},"outputs":[],"source":["from IPython.display import Image\n","Image(filename = f\"/content/yolov7/runs/train/{train_run_name}/results.png\", width=1000)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"h90_4rFQx0mp"},"outputs":[],"source":["#@title ## Export to Google Drive or Download training results {display-mode: \"form\"}\n","\n","training_results = \"Export_Google_Drive\" #@param [\"Export_Google_Drive\", \"Download\"]\n","#@markdown - Open `yolov7/runs/train/train_run_name/weights` in the File Explorer (Folder symbol on the left\n","#@markdown side bar) and delete all model weights **except `best.pt`** to decrease the size of your train folder.\n","#@markdown ---\n","\n","#@markdown ### Path for saving training results in Google Drive:\n","GDrive_save_path = \"MyDrive/Training_results/YOLOv7\"  #@param {type: \"string\"}\n","\n","if training_results == \"Export_Google_Drive\":\n","  %mkdir -p /content/drive/{GDrive_save_path}\n","  %cp -ai /content/yolov7/runs/train/{train_run_name} /content/drive/{GDrive_save_path}\n","elif training_results == \"Download\":\n","  %cd /content/yolov7/runs/train\n","  !zip -rq {train_run_name}.zip {train_run_name}\n","  from google.colab import files\n","  files.download(f\"{train_run_name}.zip\")"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"k54rL7jSM_ni"},"source":["# Model validation\n","\n","Check the performance of your model on the dataset valid split.\n","\n","> Copy the validation results (cell output) and save to .txt file, as they will not be saved automatically.\n","\n","Use `--task test` to validate on the dataset test split."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"pPKGJ1k8NDmo"},"outputs":[],"source":["%cd /content/yolov7\n","\n","!python test.py \\\n","--name {train_run_name}_validate \\\n","--weights runs/train/{train_run_name}/weights/best.pt \\\n","--data {dataset_location}/data.yaml \\\n","--img {image_size} \\\n","#--task test"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["#@title ## Export to Google Drive or Download validation results {display-mode: \"form\"}\n","\n","validation_results = \"Export_Google_Drive\" #@param [\"Export_Google_Drive\", \"Download\"]\n","#@markdown ---\n","\n","#@markdown ### Path for saving validation results in Google Drive:\n","GDrive_save_path = \"MyDrive/Training_results/YOLOv7\"  #@param {type: \"string\"}\n","\n","if validation_results == \"Export_Google_Drive\":\n","  %mkdir -p /content/drive/{GDrive_save_path}\n","  %cp -ai /content/yolov7/runs/test/{train_run_name}_validate /content/drive/{GDrive_save_path}\n","elif validation_results == \"Download\":\n","  %cd /content/yolov7/runs/test\n","  !zip -rq {train_run_name}_validate.zip {train_run_name}_validate\n","  from google.colab import files\n","  files.download(f\"{train_run_name}_validate.zip\")"]},{"cell_type":"markdown","metadata":{"id":"Rs7bZGuQROhk"},"source":["# Model inference\n","\n","Test the detection accuracy of your model on the dataset test split."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"T99Qs1noRTbb"},"outputs":[],"source":["#@markdown #### Decrease confidence threshold to detect objects with lower confidence score:\n","confidence_threshold = 0.5 #@param {type:\"slider\", min:0.1, max:1, step:0.1}\n","#@markdown #### Increase IoU threshold if the same object is detected multiple times:\n","iou_threshold = 0.5 #@param {type:\"slider\", min:0.1, max:1, step:0.1}\n","\n","%cd /content/yolov7\n","\n","!python detect.py \\\n","--name {train_run_name}_detect \\\n","--weights runs/train/{train_run_name}/weights/best.pt \\\n","--source {dataset_location}/test/images \\\n","--img {image_size} \\\n","--conf-thres {confidence_threshold} \\\n","--iou-thres {iou_threshold}"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"3_XwmhjIXnFt"},"source":["## Show inference results on test images"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"FsskeC4jRrj8"},"outputs":[],"source":["import glob\n","from IPython.display import Image, display\n","\n","for imageName in glob.glob(f\"/content/yolov7/runs/detect/{train_run_name}_detect/*.jpg\"):\n","  display(Image(filename=imageName))\n","  print(\"\\n\")"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"KiU6Qt79ShXJ"},"source":["# Model conversion\n","\n","**Go to https://tools.luxonis.com/:**\n","\n","- Select `YoloV7 (detection only)` as Yolo Version.\n","- Rename your model weights file from `best.pt` to e.g. `yolov7tiny_320.pt`.\n","- Select your model weights file (`yolov7tiny_320.pt`) for upload.\n","- Use your image size (e.g. `320`) as input shape.\n","- Open the `Advanced options` and choose `Shaves: 4`.\n","- Hit `Submit` to upload your model weights and download the converted ONNX, OpenVINO and .blob models.\n","\n","**Recommended number of shaves the model can use is 4-5 for the Insect Detect camera trap!**\n","\n","> More information on model conversion can be found at the [DepthAI docs](https://docs.luxonis.com/en/latest/pages/model_conversion/).\n","\n","> More information on the number of shaves can be found at the [DepthAI FAQ](https://docs.luxonis.com/en/latest/pages/faq/#what-are-the-shaves)."]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["## Generate JSON config file\n","\n","Together with the converted model, a .json config file with model specific settings will be created after following the conversion steps at https://tools.luxonis.com/.\n","\n","> To set the correct class/label name(s) and adjust the confidence or IoU threshold, you can create and download your own .json config file in the following step (or change it directly in the .json file you downloaded from tools.luxonis.com)."]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["#@markdown ### Name for the JSON config file:\n","json_name = \"yolov7_320\" #@param {type: \"string\"}\n","#@markdown ---\n","\n","image_size = 320 #@param {type: \"integer\"}\n","number_classes = 1 #@param {type: \"integer\"}\n","#@markdown ---\n","\n","#@markdown #### For several classes/labels: **[\"class1\", \"class2\", \"class3\"]**\n","labels = [\"insect\"] #@param {type: \"raw\"}\n","#@markdown ---\n","\n","#@markdown #### Decrease confidence threshold to detect objects with lower confidence score:\n","confidence_threshold = 0.5 #@param {type:\"slider\", min:0.1, max:1, step:0.1}\n","#@markdown #### Increase IoU threshold if the same object is detected multiple times:\n","iou_threshold = 0.5 #@param {type:\"slider\", min:0.1, max:1, step:0.1}\n","\n","masks = {\n","  f\"side{int(image_size/8)}\" : [0,1,2],\n","  f\"side{int(image_size/16)}\" : [3,4,5],\n","  f\"side{int(image_size/32)}\" : [6,7,8]\n","}\n","\n","!wget -L https://raw.githubusercontent.com/luxonis/depthai-experiments/master/gen2-yolo/device-decoding/json/yolov5.json -P /content/\n","\n","import json\n","with open(\"/content/yolov5.json\", \"r\") as f:\n","  json_data = json.load(f)\n","  json_data[\"nn_config\"][\"input_size\"] = f\"{image_size}x{image_size}\"\n","  json_data[\"nn_config\"][\"NN_specific_metadata\"][\"classes\"] = number_classes\n","  json_data[\"nn_config\"][\"NN_specific_metadata\"][\"anchor_masks\"] = masks\n","  json_data[\"nn_config\"][\"NN_specific_metadata\"][\"iou_threshold\"] = iou_threshold\n","  json_data[\"nn_config\"][\"NN_specific_metadata\"][\"confidence_threshold\"] = confidence_threshold\n","  json_data[\"mappings\"][\"labels\"] = labels\n","\n","with open(f\"/content/{json_name}.json\", \"w\") as f:\n","  json.dump(json_data, f, indent = 4)\n","\n","from google.colab import files\n","files.download(f\"/content/{json_name}.json\")"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"g_SAn96loGK-"},"source":["# Model deployment\n","\n","That's it! You trained your own [YOLOv7](https://github.com/WongKinYiu/yolov7) object detection model with your custom dataset and converted it to .blob format which is necessary to run inference on the [Luxonis OAK devices](https://docs.luxonis.com/projects/hardware/en/latest/).\n","\n","> To deploy the YOLOv7-tiny model on your OAK you can check out the Luxonis GitHub repository for [on-device decoding](https://github.com/luxonis/depthai-experiments/tree/master/gen2-yolo/device-decoding) or use the deployment options from the [**Insect Detect Docs**](https://maxsitt.github.io/insect-detect-docs/software/programming/) (e.g. for continuous automated insect monitoring with the DIY camera trap)."]}],"metadata":{"accelerator":"GPU","colab":{"private_outputs":true,"provenance":[{"file_id":"1mmZyaW3vUxkmnOThl-J2m65Nomj6Qhtr","timestamp":1678209271498},{"file_id":"https://github.com/maxsitt/insect-detect-ml/blob/main/notebooks/YOLOv5_detection_training_OAK_conversion.ipynb","timestamp":1678184163562},{"file_id":"1CDz0HUpYTTLxmvPpCx5b2nVyjY_LIYQ6","timestamp":1671662125129}]},"gpuClass":"standard","kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]"},"vscode":{"interpreter":{"hash":"baf2788c67905bf5eabce425833f665485fde887eca8cd7474f373ca3e9af677"}}},"nbformat":4,"nbformat_minor":0}
